{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_ocr_testing.ipynb\n",
    "## Pruebas de Extracción OCR\n",
    "\n",
    "Objetivo: Prototipar y validar OCR (Landing AI vs DeepSeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dependencias del proyecto importadas correctamente.\n",
      "Raíz del proyecto establecida en: c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Configuración de Path ---\n",
    "# Añadir el directorio PADRE (la raíz del proyecto) al path\n",
    "# Esto es crucial porque el notebook está en 'notebooks/' y 'src' está en el nivel superior.\n",
    "# .../Agente-Multimodal-Liquidador/\n",
    "#    ├── notebooks/ (Aquí está el notebook)\n",
    "#    └── src/       (Esto es lo que queremos importar)\n",
    "#\n",
    "# Path.cwd() -> .../notebooks\n",
    "# Path.cwd().parent -> .../ (la raíz del proyecto)\n",
    "#\n",
    "# Así, Python puede encontrar 'src'\n",
    "PROJECT_ROOT = str(Path.cwd().parent)\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# --- Importaciones del Proyecto ---\n",
    "# Ahora que el __init__.py de 'extractors' está corregido, podemos importar todo.\n",
    "\n",
    "\n",
    "# Importa utilidades\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.config import (\n",
    "    EXCEL_IMAGES_DIR, \n",
    "    PDF_IMAGES_DIR, \n",
    "    EXTRACTED_TEXT_DIR,     # Lo usaremos para probar el parser\n",
    "    EXTRACTED_TABLES_DIR    # Para ver la salida del parser\n",
    ")\n",
    "\n",
    "# --- Configuración de Logging ---\n",
    "# Configura el logger para que puedas ver los mensajes INFO en la salida del notebook\n",
    "logger = get_logger(__name__)\n",
    "logging.basicConfig(level=logging.INFO) \n",
    "\n",
    "print(\"✅ Dependencias del proyecto importadas correctamente.\")\n",
    "print(f\"Raíz del proyecto establecida en: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verificar Imágenes Disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes de Excel: 0\n",
      "Imágenes de PDF: 1\n",
      "Total: 1\n",
      "\n",
      "Primeras imágenes:\n",
      "  - 25105 25106 25107 & 25108 MV SKY KNIGHT - VAL TISUR_page_1.png\n"
     ]
    }
   ],
   "source": [
    "# Listar imágenes disponibles\n",
    "excel_images = list(EXCEL_IMAGES_DIR.glob(\"*.png\"))\n",
    "pdf_images = list(PDF_IMAGES_DIR.glob(\"*.png\"))\n",
    "all_images = excel_images + pdf_images\n",
    "\n",
    "print(f\"Imágenes de Excel: {len(excel_images)}\")\n",
    "print(f\"Imágenes de PDF: {len(pdf_images)}\")\n",
    "print(f\"Total: {len(all_images)}\")\n",
    "\n",
    "if all_images:\n",
    "    print(f\"\\nPrimeras imágenes:\")\n",
    "    for img in all_images[:5]:\n",
    "        print(f\"  - {img.name}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No hay imágenes. Ejecuta notebook 01 primero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar OCR Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-07 22:27:58,538 - src.extractors.ocr_extractor - INFO - Extractor OCR iniciado con el proveedor: landing_ai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.extractors.ocr_extractor:Extractor OCR iniciado con el proveedor: landing_ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-07 22:27:58,541 - src.extractors.ocr_extractor - ERROR - Falta LANDING_AI_API_KEY en el archivo .env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:src.extractors.ocr_extractor:Falta LANDING_AI_API_KEY en el archivo .env\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Landing AI extractor inicializado\n"
     ]
    }
   ],
   "source": [
    "# Crear extractor\n",
    "# Cambiar provider en .env: OCR_PROVIDER=landing_ai o deepseeker\n",
    "from src.extractors import OCRExtractor\n",
    "\n",
    "extractor_landing = OCRExtractor(provider=\"landing_ai\")\n",
    "print(\"✅ Landing AI extractor inicializado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prueba OCR: Landing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con primera imagen\n",
    "if excel_images:\n",
    "    test_image = excel_images[0]\n",
    "    print(f\"Testing Landing AI con: {test_image.name}\")\n",
    "    \n",
    "    result_landing = extractor_landing.extract_text(str(test_image))\n",
    "    \n",
    "    print(f\"\\nResultado:\")\n",
    "    print(f\"  Status: {result_landing.get('status')}\")\n",
    "    print(f\"  Provider: {result_landing.get('provider')}\")\n",
    "    \n",
    "    if result_landing.get('status') == 'success':\n",
    "        text = result_landing.get('text', '')\n",
    "        print(f\"  Texto extraído (primeros 200 chars):\")\n",
    "        print(f\"  {text[:200]}...\")\n",
    "        print(f\"  Total chars: {len(text)}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ Error: {result_landing.get('message')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prueba OCR: DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con DeepSeek\n",
    "if excel_images:\n",
    "    test_image = excel_images[0]\n",
    "    print(f\"Testing DeepSeek con: {test_image.name}\")\n",
    "    \n",
    "    result_deepseek = extractor_deepseek.extract_text(str(test_image))\n",
    "    \n",
    "    print(f\"\\nResultado:\")\n",
    "    print(f\"  Status: {result_deepseek.get('status')}\")\n",
    "    print(f\"  Provider: {result_deepseek.get('provider')}\")\n",
    "    \n",
    "    if result_deepseek.get('status') == 'success':\n",
    "        text = result_deepseek.get('text', '')\n",
    "        print(f\"  Texto extraído (primeros 200 chars):\")\n",
    "        print(f\"  {text[:200]}...\")\n",
    "        print(f\"  Total chars: {len(text)}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ Error: {result_deepseek.get('message')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extracción de Estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar estructura del texto extraído\n",
    "if excel_images and 'result_landing' in locals():\n",
    "    extracted_text = result_landing.get('text', '')\n",
    "    \n",
    "    structure = extractor_landing.extract_structure(extracted_text)\n",
    "    \n",
    "    print(\"Estructura detectada:\")\n",
    "    print(f\"  Líneas: {len(structure.get('lines', []))}\")\n",
    "    print(f\"  Tablas detectadas: {len(structure.get('tables', []))}\")\n",
    "    \n",
    "    key_fields = structure.get('key_fields', {})\n",
    "    print(f\"\\n  Campos clave:\")\n",
    "    print(f\"    - Fechas: {key_fields.get('dates', [])}\")\n",
    "    print(f\"    - Montos: {key_fields.get('amounts', [])}\")\n",
    "    print(f\"    - Conceptos: {len(key_fields.get('concepts', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parser: Estructuración JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from src.extractors import StructureParser, LiquidacionData\n",
    "from src.utils.config import LLM_MODEL\n",
    "\n",
    "# --- 1. Inicializar el LLM y el Parser ---\n",
    "# El StructureParser necesita una instancia de un LLM para funcionar.\n",
    "# (Asegúrate de que tu OPENAI_API_KEY esté en el .env)\n",
    "try:\n",
    "    llm = ChatOpenAI(model=LLM_MODEL, temperature=0)\n",
    "    \n",
    "    # ¡CORRECCIÓN 1!\n",
    "    # Le pasamos el 'llm' y el 'schema' (LiquidacionData) al inicializar.\n",
    "    parser = StructureParser(llm=llm, schema=LiquidacionData)\n",
    "    \n",
    "    print(f\"✅ Parser inicializado con modelo: {LLM_MODEL}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error inicializando el LLM. ¿Está la API Key en tu .env? Error: {e}\")\n",
    "    parser = None\n",
    "\n",
    "\n",
    "# --- 2. Ejecutar el Parseo ---\n",
    "# Asegúrate de haber ejecutado la celda anterior \"Prueba OCR: Landing AI\"\n",
    "# para que 'result_landing' exista.\n",
    "\n",
    "if parser and 'result_landing' in locals() and result_landing.get('status') == 'success':\n",
    "    extracted_text = result_landing.get('text', '')\n",
    "    \n",
    "    if not extracted_text:\n",
    "        print(\"⚠️ El texto extraído de Landing AI está vacío.\")\n",
    "    else:\n",
    "        print(f\"\\nIniciando parseo con LLM (esto puede tardar unos segundos)...\")\n",
    "        \n",
    "        try:\n",
    "            # ¡CORRECCIÓN 2!\n",
    "            # El método se llama 'parse_document()', no 'parse()'.\n",
    "            structured_data = parser.parse_document(extracted_text)\n",
    "            \n",
    "            print(\"\\n--- ✅ ¡Parseo Exitoso con LLM! ---\")\n",
    "            # Imprimimos el JSON completo. Es la mejor forma de ver la estructura.\n",
    "            print(json.dumps(structured_data, indent=2, ensure_ascii=False))\n",
    "            \n",
    "            print(\"\\n--- Acceso a datos ---\")\n",
    "            # Podemos acceder a los datos usando las claves del Pydantic (LiquidacionData)\n",
    "            print(f\"Cliente: {structured_data.get('cliente_nombre')}\")\n",
    "            \n",
    "            # Usamos .get() con un diccionario vacío {} como default para evitar errores\n",
    "            total = structured_data.get('resumen_financiero', {}).get('total_general')\n",
    "            print(f\"Total General: {total}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Esto atrapará errores de Pydantic (Validación) o del API de OpenAI\n",
    "            print(f\"\\n--- ❌ ¡Error en el Parseo con LLM! ---\")\n",
    "            logger.error(f\"Fallo el parseo con LLM: {e}\", exc_info=True)\n",
    "            print(str(e))\n",
    "            \n",
    "else:\n",
    "    if not parser:\n",
    "        print(\"⚠️ Parser no inicializado. Revisa el error de API Key.\")\n",
    "    else:\n",
    "        print(\"⚠️ No se encontró 'result_landing' o la extracción OCR falló.\")\n",
    "        print(\"   Asegúrate de ejecutar la celda '3. Prueba OCR: Landing AI' primero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparación: Landing AI vs DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar calidad de extracción\n",
    "if 'result_landing' in locals() and 'result_deepseek' in locals():\n",
    "    text_landing = result_landing.get('text', '')\n",
    "    text_deepseek = result_deepseek.get('text', '')\n",
    "    \n",
    "    print(\"COMPARACIÓN: Landing AI vs DeepSeek\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nLanding AI:\")\n",
    "    print(f\"  - Status: {result_landing.get('status')}\")\n",
    "    print(f\"  - Caracteres: {len(text_landing)}\")\n",
    "    print(f\"  - Líneas: {len(text_landing.split(chr(10)))}\")\n",
    "    \n",
    "    print(f\"\\nDeepSeek:\")\n",
    "    print(f\"  - Status: {result_deepseek.get('status')}\")\n",
    "    print(f\"  - Caracteres: {len(text_deepseek)}\")\n",
    "    print(f\"  - Líneas: {len(text_deepseek.split(chr(10)))}\")\n",
    "    \n",
    "    # Similitud aproximada\n",
    "    if text_landing and text_deepseek:\n",
    "        common_chars = len(set(text_landing) & set(text_deepseek))\n",
    "        similarity = common_chars / max(len(text_landing), len(text_deepseek)) * 100\n",
    "        print(f\"\\nSimilitud: {similarity:.1f}%\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Procesar todas las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar lote de imágenes\n",
    "print(\"Procesando todas las imágenes con OCR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = {\n",
    "    'success': 0,\n",
    "    'error': 0,\n",
    "    'total': len(all_images)\n",
    "}\n",
    "\n",
    "for idx, image in enumerate(all_images[:5], 1):  # Primeras 5 para testing\n",
    "    print(f\"\\n[{idx}/{min(5, len(all_images))}] {image.name}\")\n",
    "    \n",
    "    result = extractor_landing.extract_text(str(image))\n",
    "    \n",
    "    if result.get('status') == 'success':\n",
    "        text = result.get('text', '')\n",
    "        print(f\"  ✅ Extraído: {len(text)} caracteres\")\n",
    "        results_summary['success'] += 1\n",
    "    else:\n",
    "        print(f\"  ❌ Error: {result.get('message')}\")\n",
    "        results_summary['error'] += 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RESUMEN:\")\n",
    "print(f\"  Exitosos: {results_summary['success']}\")\n",
    "print(f\"  Errores: {results_summary['error']}\")\n",
    "print(f\"  Total: {results_summary['total']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar resultados OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar ejemplo de OCR + estructura en JSON\n",
    "if 'structured' in locals():\n",
    "    output_file = Path('ocr_test_output.json')\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(structured, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"✅ Resultados guardados en: {output_file}\")\n",
    "    print(f\"\\nPrimeras líneas:\")\n",
    "    print(json.dumps(structured, ensure_ascii=False, indent=2)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RESUMEN: EXTRACCIÓN OCR\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✅ Imágenes procesadas: {len(all_images)}\")\n",
    "print(f\"\\n✅ Providers testeados:\")\n",
    "print(f\"   - Landing AI (Enterprise)\")\n",
    "print(f\"   - DeepSeek (Económico)\")\n",
    "print(f\"\\n✅ Estructura detectada:\")\n",
    "print(f\"   - Fechas\")\n",
    "print(f\"   - Montos (S/, USD)\")\n",
    "print(f\"   - Conceptos\")\n",
    "print(f\"   - Tablas\")\n",
    "print(f\"\\n✅ Próximo paso:\")\n",
    "print(f\"   → Notebook 03: CLIP Embeddings & Espacio Compartido\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
