{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_ocr_testing.ipynb\n",
    "## Pruebas de Extracción OCR\n",
    "\n",
    "Objetivo: Prototipar y validar OCR (Landing AI vs DeepSeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'process_all_extracted_text' from 'src.extractors.structure_parser' (c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\src\\extractors\\structure_parser.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Añadir el directorio PADRE (la raíz del proyecto) al path\u001b[39;00m\n\u001b[32m      4\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(Path.cwd().parent))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextractors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OCRExtractor\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EXCEL_IMAGES_DIR, PDF_IMAGES_DIR\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\src\\extractors\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mextractors/__init__.py\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;03mExporta las clases y funciones principales del módulo de extracción.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextractors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mocr_extractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OCRExtractor, process_all_images\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextractors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructure_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StructureParser, process_all_extracted_text\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'process_all_extracted_text' from 'src.extractors.structure_parser' (c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\src\\extractors\\structure_parser.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# Añadir el directorio PADRE (la raíz del proyecto) al path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.extractors import OCRExtractor\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.config import EXCEL_IMAGES_DIR, PDF_IMAGES_DIR\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verificar Imágenes Disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXCEL_IMAGES_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Listar imágenes disponibles\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m excel_images = \u001b[38;5;28mlist\u001b[39m(\u001b[43mEXCEL_IMAGES_DIR\u001b[49m.glob(\u001b[33m\"\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      3\u001b[39m pdf_images = \u001b[38;5;28mlist\u001b[39m(PDF_IMAGES_DIR.glob(\u001b[33m\"\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      4\u001b[39m all_images = excel_images + pdf_images\n",
      "\u001b[31mNameError\u001b[39m: name 'EXCEL_IMAGES_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Listar imágenes disponibles\n",
    "excel_images = list(EXCEL_IMAGES_DIR.glob(\"*.png\"))\n",
    "pdf_images = list(PDF_IMAGES_DIR.glob(\"*.png\"))\n",
    "all_images = excel_images + pdf_images\n",
    "\n",
    "print(f\"Imágenes de Excel: {len(excel_images)}\")\n",
    "print(f\"Imágenes de PDF: {len(pdf_images)}\")\n",
    "print(f\"Total: {len(all_images)}\")\n",
    "\n",
    "if all_images:\n",
    "    print(f\"\\nPrimeras imágenes:\")\n",
    "    for img in all_images[:5]:\n",
    "        print(f\"  - {img.name}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No hay imágenes. Ejecuta notebook 01 primero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar OCR Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear extractor\n",
    "# Cambiar provider en .env: OCR_PROVIDER=landing_ai o deepseek\n",
    "\n",
    "extractor_landing = OCRExtractor(provider=\"landing_ai\")\n",
    "print(\"✅ Landing AI extractor inicializado\")\n",
    "\n",
    "extractor_deepseek = OCRExtractor(provider=\"deepseek\")\n",
    "print(\"✅ DeepSeek extractor inicializado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prueba OCR: Landing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con primera imagen\n",
    "if excel_images:\n",
    "    test_image = excel_images[0]\n",
    "    print(f\"Testing Landing AI con: {test_image.name}\")\n",
    "    \n",
    "    result_landing = extractor_landing.extract_text(str(test_image))\n",
    "    \n",
    "    print(f\"\\nResultado:\")\n",
    "    print(f\"  Status: {result_landing.get('status')}\")\n",
    "    print(f\"  Provider: {result_landing.get('provider')}\")\n",
    "    \n",
    "    if result_landing.get('status') == 'success':\n",
    "        text = result_landing.get('text', '')\n",
    "        print(f\"  Texto extraído (primeros 200 chars):\")\n",
    "        print(f\"  {text[:200]}...\")\n",
    "        print(f\"  Total chars: {len(text)}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ Error: {result_landing.get('message')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prueba OCR: DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con DeepSeek\n",
    "if excel_images:\n",
    "    test_image = excel_images[0]\n",
    "    print(f\"Testing DeepSeek con: {test_image.name}\")\n",
    "    \n",
    "    result_deepseek = extractor_deepseek.extract_text(str(test_image))\n",
    "    \n",
    "    print(f\"\\nResultado:\")\n",
    "    print(f\"  Status: {result_deepseek.get('status')}\")\n",
    "    print(f\"  Provider: {result_deepseek.get('provider')}\")\n",
    "    \n",
    "    if result_deepseek.get('status') == 'success':\n",
    "        text = result_deepseek.get('text', '')\n",
    "        print(f\"  Texto extraído (primeros 200 chars):\")\n",
    "        print(f\"  {text[:200]}...\")\n",
    "        print(f\"  Total chars: {len(text)}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ Error: {result_deepseek.get('message')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extracción de Estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar estructura del texto extraído\n",
    "if excel_images and 'result_landing' in locals():\n",
    "    extracted_text = result_landing.get('text', '')\n",
    "    \n",
    "    structure = extractor_landing.extract_structure(extracted_text)\n",
    "    \n",
    "    print(\"Estructura detectada:\")\n",
    "    print(f\"  Líneas: {len(structure.get('lines', []))}\")\n",
    "    print(f\"  Tablas detectadas: {len(structure.get('tables', []))}\")\n",
    "    \n",
    "    key_fields = structure.get('key_fields', {})\n",
    "    print(f\"\\n  Campos clave:\")\n",
    "    print(f\"    - Fechas: {key_fields.get('dates', [])}\")\n",
    "    print(f\"    - Montos: {key_fields.get('amounts', [])}\")\n",
    "    print(f\"    - Conceptos: {len(key_fields.get('concepts', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parser: Estructuración JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar StructureParser para mejor formato\n",
    "parser = StructureParser()\n",
    "\n",
    "if excel_images and 'result_landing' in locals():\n",
    "    extracted_text = result_landing.get('text', '')\n",
    "    \n",
    "    structured = parser.parse(extracted_text)\n",
    "    \n",
    "    print(\"\\nDatos estructurados:\")\n",
    "    print(f\"  Status: {structured.get('status', 'N/A')}\")\n",
    "    print(f\"  Tablas: {len(structured.get('tables', []))}\")\n",
    "    \n",
    "    fields = structured.get('fields', {})\n",
    "    print(f\"\\n  Campos extraídos:\")\n",
    "    print(f\"    - Fechas: {fields.get('dates', [])}\")\n",
    "    print(f\"    - Montos: {fields.get('amounts', [])}\")\n",
    "    print(f\"    - Cuentas: {fields.get('accounts', [])}\")\n",
    "    \n",
    "    # Mostrar primera tabla si existe\n",
    "    tables = structured.get('tables', [])\n",
    "    if tables:\n",
    "        print(f\"\\n  Primera tabla:\")\n",
    "        table = tables[0]\n",
    "        print(f\"    Headers: {table.get('headers', [])}\")\n",
    "        print(f\"    Filas: {table.get('row_count', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparación: Landing AI vs DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar calidad de extracción\n",
    "if 'result_landing' in locals() and 'result_deepseek' in locals():\n",
    "    text_landing = result_landing.get('text', '')\n",
    "    text_deepseek = result_deepseek.get('text', '')\n",
    "    \n",
    "    print(\"COMPARACIÓN: Landing AI vs DeepSeek\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nLanding AI:\")\n",
    "    print(f\"  - Status: {result_landing.get('status')}\")\n",
    "    print(f\"  - Caracteres: {len(text_landing)}\")\n",
    "    print(f\"  - Líneas: {len(text_landing.split(chr(10)))}\")\n",
    "    \n",
    "    print(f\"\\nDeepSeek:\")\n",
    "    print(f\"  - Status: {result_deepseek.get('status')}\")\n",
    "    print(f\"  - Caracteres: {len(text_deepseek)}\")\n",
    "    print(f\"  - Líneas: {len(text_deepseek.split(chr(10)))}\")\n",
    "    \n",
    "    # Similitud aproximada\n",
    "    if text_landing and text_deepseek:\n",
    "        common_chars = len(set(text_landing) & set(text_deepseek))\n",
    "        similarity = common_chars / max(len(text_landing), len(text_deepseek)) * 100\n",
    "        print(f\"\\nSimilitud: {similarity:.1f}%\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Procesar todas las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar lote de imágenes\n",
    "print(\"Procesando todas las imágenes con OCR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = {\n",
    "    'success': 0,\n",
    "    'error': 0,\n",
    "    'total': len(all_images)\n",
    "}\n",
    "\n",
    "for idx, image in enumerate(all_images[:5], 1):  # Primeras 5 para testing\n",
    "    print(f\"\\n[{idx}/{min(5, len(all_images))}] {image.name}\")\n",
    "    \n",
    "    result = extractor_landing.extract_text(str(image))\n",
    "    \n",
    "    if result.get('status') == 'success':\n",
    "        text = result.get('text', '')\n",
    "        print(f\"  ✅ Extraído: {len(text)} caracteres\")\n",
    "        results_summary['success'] += 1\n",
    "    else:\n",
    "        print(f\"  ❌ Error: {result.get('message')}\")\n",
    "        results_summary['error'] += 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RESUMEN:\")\n",
    "print(f\"  Exitosos: {results_summary['success']}\")\n",
    "print(f\"  Errores: {results_summary['error']}\")\n",
    "print(f\"  Total: {results_summary['total']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar resultados OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar ejemplo de OCR + estructura en JSON\n",
    "if 'structured' in locals():\n",
    "    output_file = Path('ocr_test_output.json')\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(structured, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"✅ Resultados guardados en: {output_file}\")\n",
    "    print(f\"\\nPrimeras líneas:\")\n",
    "    print(json.dumps(structured, ensure_ascii=False, indent=2)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RESUMEN: EXTRACCIÓN OCR\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✅ Imágenes procesadas: {len(all_images)}\")\n",
    "print(f\"\\n✅ Providers testeados:\")\n",
    "print(f\"   - Landing AI (Enterprise)\")\n",
    "print(f\"   - DeepSeek (Económico)\")\n",
    "print(f\"\\n✅ Estructura detectada:\")\n",
    "print(f\"   - Fechas\")\n",
    "print(f\"   - Montos (S/, USD)\")\n",
    "print(f\"   - Conceptos\")\n",
    "print(f\"   - Tablas\")\n",
    "print(f\"\\n✅ Próximo paso:\")\n",
    "print(f\"   → Notebook 03: CLIP Embeddings & Espacio Compartido\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
