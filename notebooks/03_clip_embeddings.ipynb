{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_clip_embeddings.ipynb\n",
    "## (Refactorizado) Paso 4: Embeddings CLIP y Espacio Compartido\n",
    "\n",
    "**Objetivo:** Verificar que el espacio vectorial multimodal funciona.\n",
    "\n",
    "Comprobaremos que podemos comparar:\n",
    "1.  **Im√°genes** (de Excel, generadas en el Paso 1)\n",
    "2.  **Textos** (el JSON estructurado, generado en el Paso 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ra√≠z del proyecto establecida en: c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\n",
      "‚úÖ Entorno configurado. Logging listo.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# --- Celda de Configuraci√≥n Est√°ndar ---\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import src.utils.config \n",
    "from src.utils.config import (\n",
    "    CLIP_MODEL_NAME, \n",
    "    EXCEL_IMAGES_DIR,       # <- Fuente de Im√°genes\n",
    "    EXTRACTED_TABLES_DIR  # <- Fuente de Textos (JSONs)\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Ra√≠z del proyecto establecida en: {PROJECT_ROOT}\")\n",
    "print(\"‚úÖ Entorno configurado. Logging listo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inicializar CLIP Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-08 11:40:38,933 - src.embeddings.clip_encoder - INFO - Cargando modelo CLIP: openai/clip-vit-base-patch32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:Cargando modelo CLIP: openai/clip-vit-base-patch32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-08 11:40:38,935 - src.embeddings.clip_encoder - INFO - Usando device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:Usando device: cpu\n",
      "c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Usuario\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-08 11:40:55,312 - src.embeddings.clip_encoder - INFO - CLIP encoder cargado exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:CLIP encoder cargado exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CLIP encoder listo.\n",
      "   Modelo: openai/clip-vit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "# Esta clase ya est√° refactorizada y funciona bien\n",
    "from src.embeddings.clip_encoder import CLIPEncoder\n",
    "\n",
    "encoder = CLIPEncoder(model_name=CLIP_MODEL_NAME)\n",
    "print(\"‚úÖ CLIP encoder listo.\")\n",
    "print(f\"   Modelo: {CLIP_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Codificar una Imagen (de Excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificando imagen: 10841- INFORME GENERAL - MN - SKY KNIGHT  -  LAS BAMBAS   - 09 -10 -2025 (1)_chunk_r0_c0.png\n",
      "2025-11-08 11:40:58,872 - src.embeddings.clip_encoder - INFO - Codificando imagen: c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\data\\images\\excel_images\\10841- INFORME GENERAL - MN - SKY KNIGHT  -  LAS BAMBAS   - 09 -10 -2025 (1)_chunk_r0_c0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:Codificando imagen: c:\\Users\\Usuario\\Documents\\UTEC\\Liquidaciones Agent\\multidoc-agent\\data\\images\\excel_images\\10841- INFORME GENERAL - MN - SKY KNIGHT  -  LAS BAMBAS   - 09 -10 -2025 (1)_chunk_r0_c0.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-08 11:41:00,065 - src.embeddings.clip_encoder - INFO - Imagen codificada. Dimensi√≥n: (512,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:Imagen codificada. Dimensi√≥n: (512,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Embedding de IMAGEN generado:\n",
      "   - Dimensiones: (512,)\n",
      "   - Norma (debe ser ~1.0): 1.0000\n"
     ]
    }
   ],
   "source": [
    "excel_images = list(EXCEL_IMAGES_DIR.glob(\"*.png\"))\n",
    "image_embedding = None\n",
    "\n",
    "if not excel_images:\n",
    "    print(\"‚ö†Ô∏è No hay im√°genes de Excel. Ejecuta notebook 01 primero.\")\n",
    "else:\n",
    "    test_image_path = excel_images[0]\n",
    "    print(f\"Codificando imagen: {test_image_path.name}\")\n",
    "    \n",
    "    image_embedding = encoder.encode_image(str(test_image_path))\n",
    "    \n",
    "    if image_embedding is not None:\n",
    "        print(f\"\\n‚úÖ Embedding de IMAGEN generado:\")\n",
    "        print(f\"   - Dimensiones: {image_embedding.shape}\")\n",
    "        print(f\"   - Norma (debe ser ~1.0): {np.linalg.norm(image_embedding):.4f}\")\n",
    "    else:\n",
    "        print(\"‚ùå Error al codificar imagen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Codificar Texto (del JSON Estructurado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codificando texto (JSON) de: 25105 25106 25107 & 25108 MV SKY KNIGHT - VAL TISUR_structure.json\n",
      "Contenido (primeros 200 chars): {\"numero_factura\": null, \"fecha_emision\": null, \"cliente_nombre\": null, \"items_detalle\": [], \"resumen_financiero\": {\"subtotal\": null, \"impuestos\": null, \"total_general\": 0.0}}...\n",
      "2025-11-08 11:41:08,121 - src.embeddings.clip_encoder - INFO - Codificando texto (primeros 50 chars): {\"numero_factura\": null, \"fecha_emision\": null, \"c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:Codificando texto (primeros 50 chars): {\"numero_factura\": null, \"fecha_emision\": null, \"c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-08 11:41:08,304 - src.embeddings.clip_encoder - INFO - Texto codificado. Dimensi√≥n: (512,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.clip_encoder:Texto codificado. Dimensi√≥n: (512,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Embedding de TEXTO (JSON) generado:\n",
      "   - Dimensiones: (512,)\n",
      "   - Norma (debe ser ~1.0): 1.0000\n"
     ]
    }
   ],
   "source": [
    "json_files = list(EXTRACTED_TABLES_DIR.glob(\"*_structure.json\"))\n",
    "text_embedding = None\n",
    "\n",
    "if not json_files:\n",
    "    print(\"‚ö†Ô∏è No hay archivos JSON estructurados. Ejecuta notebook 02 (incluyendo el Paso 3 de Parseo) primero.\")\n",
    "else:\n",
    "    test_json_path = json_files[0]\n",
    "    print(f\"Codificando texto (JSON) de: {test_json_path.name}\")\n",
    "    \n",
    "    # Leemos el contenido del JSON y lo convertimos en un string\n",
    "    # Esto coincide con la l√≥gica de 'process_all_multimodal' en clip_encoder.py\n",
    "    with open(test_json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        text_content = json.dumps(data) # Convertimos el dict a un string\n",
    "    \n",
    "    print(f\"Contenido (primeros 200 chars): {text_content[:200]}...\")\n",
    "    \n",
    "    text_embedding = encoder.encode_text(text_content)\n",
    "    \n",
    "    if text_embedding is not None:\n",
    "        print(f\"\\n‚úÖ Embedding de TEXTO (JSON) generado:\")\n",
    "        print(f\"   - Dimensiones: {text_embedding.shape}\")\n",
    "        print(f\"   - Norma (debe ser ~1.0): {np.linalg.norm(text_embedding):.4f}\")\n",
    "    else:\n",
    "        print(\"‚ùå Error al codificar texto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ‚≠ê VERIFICAR ESPACIO COMPARTIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICACI√ìN ESPACIO VECTORIAL COMPARTIDO (IMAGEN vs TEXTO/JSON)\n",
      "============================================================\n",
      "1. Dimensionalidad:\n",
      "   Imagen: 512\n",
      "   Texto: 512\n",
      "   ¬øIguales? ‚úÖ S√ç\n",
      "\n",
      "2. Similitud Coseno:\n",
      "   (Imagen de Excel vs JSON de PDF)\n",
      "   Similitud: 0.2220\n",
      "\n",
      "3. Interpretaci√≥n:\n",
      "   - Una similitud de 0.22 indica que los documentos NO son id√©nticos,\n",
      "     pero comparten alg√∫n contexto vago (ej. 'documento financiero').\n",
      "   - Esto es ESPERADO, ya que comparamos una imagen de Excel (Informe General)\n",
      "     con un JSON de PDF (Liquidaci√≥n TISUR).\n",
      "\n",
      "‚úÖ CONCLUSI√ìN: Imagen y texto est√°n en el MISMO espacio vectorial (512-dim).\n",
      "   El sistema puede comparar im√°genes con texto.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"VERIFICACI√ìN ESPACIO VECTORIAL COMPARTIDO (IMAGEN vs TEXTO/JSON)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if image_embedding is not None and text_embedding is not None:\n",
    "    # 1. Verificar dimensiones\n",
    "    img_dim = image_embedding.shape[0]\n",
    "    text_dim = text_embedding.shape[0]\n",
    "    \n",
    "    print(f\"1. Dimensionalidad:\")\n",
    "    print(f\"   Imagen: {img_dim}\")\n",
    "    print(f\"   Texto: {text_dim}\")\n",
    "    print(f\"   ¬øIguales? {'‚úÖ S√ç' if img_dim == text_dim else '‚ùå NO'}\")\n",
    "    \n",
    "    # 2. Calcular similitud coseno\n",
    "    # (Los vectores ya est√°n normalizados por el encoder)\n",
    "    similarity = np.dot(image_embedding, text_embedding)\n",
    "    \n",
    "    print(f\"\\n2. Similitud Coseno:\")\n",
    "    print(f\"   (Imagen de Excel vs JSON de PDF)\")\n",
    "    print(f\"   Similitud: {similarity:.4f}\")\n",
    "    \n",
    "    print(f\"\\n3. Interpretaci√≥n:\")\n",
    "    print(f\"   - Una similitud de {similarity:.2f} indica que los documentos NO son id√©nticos,\")\n",
    "    print(f\"     pero comparten alg√∫n contexto vago (ej. 'documento financiero').\")\n",
    "    print(f\"   - Esto es ESPERADO, ya que comparamos una imagen de Excel (Informe General)\")\n",
    "    print(f\"     con un JSON de PDF (Liquidaci√≥n TISUR).\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ CONCLUSI√ìN: Imagen y texto est√°n en el MISMO espacio vectorial (512-dim).\")\n",
    "    print(f\"   El sistema puede comparar im√°genes con texto.\")\n",
    "else:\n",
    "    print(\"‚ùå Faltan embeddings para comparaci√≥n. Ejecuta las celdas anteriores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resumen y Pr√≥ximos Pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMEN: PASO 4 - EMBEDDINGS (CLIP)\n",
      "============================================================\n",
      "‚úÖ Se gener√≥ embedding para 1 imagen de Excel (512-dim).\n",
      "‚úÖ Se gener√≥ embedding para 1 texto/JSON (512-dim).\n",
      "‚úÖ Se verific√≥ que ambos embeddings tienen la misma dimensionalidad.\n",
      "‚úÖ Se confirm√≥ que el pipeline est√° listo para el RAG Multimodal.\n",
      "\n",
      "üöÄ PR√ìXIMO PASO:\n",
      "   ‚Üí Notebook 04: Prototipo del Agente (Indexaci√≥n y Consulta)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RESUMEN: PASO 4 - EMBEDDINGS (CLIP)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"‚úÖ Se gener√≥ embedding para 1 imagen de Excel (512-dim).\")\n",
    "print(f\"‚úÖ Se gener√≥ embedding para 1 texto/JSON (512-dim).\")\n",
    "print(f\"‚úÖ Se verific√≥ que ambos embeddings tienen la misma dimensionalidad.\")\n",
    "print(f\"‚úÖ Se confirm√≥ que el pipeline est√° listo para el RAG Multimodal.\")\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMO PASO:\")\n",
    "print(f\"   ‚Üí Notebook 04: Prototipo del Agente (Indexaci√≥n y Consulta)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
